{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_cnn_v3","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"tEW2HBTVg4GJ","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","tf.logging.set_verbosity(tf.logging.INFO) #This way we can see the training information"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3tLzMkXYtsPz","colab_type":"code","outputId":"53c4ef15-5bed-422f-cff5-d694901fae71","executionInfo":{"status":"ok","timestamp":1544889926367,"user_tz":420,"elapsed":230,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"nWeqFh1qwgpS","colab_type":"code","outputId":"4a943205-bf24-42a5-dd00-0ae4885abcc6","executionInfo":{"status":"ok","timestamp":1544889929368,"user_tz":420,"elapsed":565,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"cell_type":"code","source":["\n","%matplotlib inline\n","filedir = './drive/My Drive/Final/CNN_data'\n","filelist = os.listdir(filedir)\n","'''\n","with open(filedir + '/' + filelist[0], 'rb') as f:\n","  X = np.load(f)\n","print(X.shape)\n","plt.imshow(X.reshape(40,61,3)[:,:,0], cmap='hot')\n","plt.show()\n","'''"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nwith open(filedir + '/' + filelist[0], 'rb') as f:\\n  X = np.load(f)\\nprint(X.shape)\\nplt.imshow(X.reshape(40,61,3)[:,:,0], cmap='hot')\\nplt.show()\\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"YFr6LPJv0rCP","colab_type":"code","outputId":"63f556e7-d333-4972-92dc-6117ea5bc9b9","executionInfo":{"status":"ok","timestamp":1544866907382,"user_tz":420,"elapsed":30062,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"cell_type":"code","source":["'''\n","X = np.zeros((300,7320))\n","Y = np.zeros(300)\n","for i in range(len(filelist)):\n","  file = filelist[i]\n","  if(file[0] == '0'):\n","    Y[i] = 0\n","  else:\n","    Y[i] = 1\n","  with open(filedir + '/' + file, 'rb') as f:\n","    data = np.load(f)\n","  assert (len(data) == 7320)\n","  X[i,:] = data\n","'''"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nX = np.zeros((300,7320))\\nY = np.zeros(300)\\nfor i in range(len(filelist)):\\n  file = filelist[i]\\n  if(file[0] == '0'):\\n    Y[i] = 0\\n  else:\\n    Y[i] = 1\\n  with open(filedir + '/' + file, 'rb') as f:\\n    data = np.load(f)\\n  assert (len(data) == 7320)\\n  X[i,:] = data\\n\""]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"2BJRQ2Sm8XuD","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(filedir + '/' + 'X', 'rb') as f:\n","  X = np.load(f)\n","with open(filedir + '/' + 'Y', 'rb') as f:\n","  Y = np.load(f).astype(np.int32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5dgKIGcqhMzf","colab_type":"code","outputId":"56532c89-778c-4eb3-961e-479b9dfa04da","executionInfo":{"status":"ok","timestamp":1544889935551,"user_tz":420,"elapsed":205,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["print('X.shape: {}\\nY.shape: {}'.format(X.shape, Y.shape))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["X.shape: (300, 7320)\n","Y.shape: (300,)\n"],"name":"stdout"}]},{"metadata":{"id":"1ad4HIun7mYC","colab_type":"code","outputId":"6f84e32b-781d-4ed5-ed1e-486dae517200","executionInfo":{"status":"ok","timestamp":1544866909018,"user_tz":420,"elapsed":31648,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["'''\n","with open(filedir + '/' + 'X', 'wb') as f:\n","  np.save(f, X)\n","with open(filedir + '/' + 'Y', 'wb') as f:\n","  np.save(f, Y)\n","'''"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nwith open(filedir + '/' + 'X', 'wb') as f:\\n  np.save(f, X)\\nwith open(filedir + '/' + 'Y', 'wb') as f:\\n  np.save(f, Y)\\n\""]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"wBXfII_IhVc3","colab_type":"code","outputId":"55e7682d-c30c-491d-a14d-d4615eba32d8","executionInfo":{"status":"ok","timestamp":1544889938694,"user_tz":420,"elapsed":229,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"cell_type":"code","source":["def cnn_model_fn(features, labels, mode):\n","  \"\"\"\n","  Custom model function for a CNN estimator object\n","  \"\"\"\n","  \n","  #Input preprocessing layer\n","  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n","  # spectographs are 40x183 pixels, and have one color channel\n","  input_layer = tf.reshape(features[\"x\"],[-1,40,61,3]) #-1 means adjust batch size so that feature data fills the dimension of (40,61,3) before the starting the next batch element\n","  \n","  #Module 1: Extraction\n","  # Computes 32 new features using a 7x11 filter with ReLU activation. Filter dimensions preserve ratios of convolution 7/40~5/28, 11/(183/3)~5/28\n","  # Padding is added to preserve width and height during convolution.\n","  # The (1,1) stride makes each new feature have same dimensions as input spectrograph\n","  # Input Tensor Shape: [batch_size, 40, 61, 3]\n","  # Output Tensor Shape: [batch_size, 40, 61, 32]\n","  conv1 = tf.layers.conv2d(\n","      inputs=input_layer,\n","      filters=32,\n","      kernel_size=[7,11],\n","      strides=(1, 1),\n","      padding=\"same\",\n","      activation=tf.nn.relu)\n","  # First max pooling layer with a 3x5 filter and stride of 2. Filter dimensions preserve ratios of shrinking filters 3/7~2/5, 5/11~2/5\n","  # The stride cuts the X's image dimensions by ceil(2)\n","  # Retains the newest 32 features\n","  # Input Tensor Shape: [batch_size, 40, 61, 32]\n","  # Output Tensor Shape: [batch_size, 20, 31, 32]\n","  pool1 = tf.layers.max_pooling2d(\n","      inputs=conv1,\n","      pool_size=[3,4],\n","      strides=(2,2),\n","      padding='same',\n","  )\n","  \n","  #Module 2: Extraction\n","  # Computes 32 new features, totaling 32+32=64 using a 7x11 filter.\n","  # Padding is added to preserve width and height.\n","  # Input Tensor Shape: [batch_size, 20, 31, 32]\n","  # Output Tensor Shape: [batch_size, 20, 31, 64]\n","  conv2 = tf.layers.conv2d(\n","      inputs=pool1,\n","      filters=64,\n","      kernel_size=[7,11],\n","      strides=(1, 1),\n","      padding=\"same\",\n","      activation=tf.nn.relu\n","  )\n","  # Second max pooling layer with a 3x5 filter and stride of 2\n","  # The stride cuts the X's image dimensions by ceil(2)\n","  # Retains the total 64 features\n","  # Input Tensor Shape: [batch_size, 20, 31, 64]\n","  # Output Tensor Shape: [batch_size, 10, 16, 64]\n","  pool2 = tf.layers.max_pooling2d(\n","      inputs=conv2,\n","      pool_size=[3,4],\n","      strides=(2,2),\n","      padding='same'\n","  )\n","  \n","  \n","  #Module 3: Prediction\n","  # Flatten tensor into a batch of vectors, just like our input\n","  # Input Tensor Shape: [batch_size, 3, 3, 3]\n","  # Output Tensor Shape: [batch_size, 10 * 16 * 64 = 10240]\n","  pool2_flattened = tf.reshape(\n","      pool2,\n","      [-1, 10 * 16 * 64]\n","  )\n","  # Densely connected layer with 1024 neurons\n","  # Input Tensor Shape: [batch_size, 10 * 16 * 64 = 10240]\n","  # Output Tensor Shape: [batch_size, 5120]\n","  dense = tf.layers.dense(\n","      inputs=pool2_flattened,\n","      units=5120,\n","      activation=tf.nn.relu)\n","  # Add dropout operation; 0.6 probability that element will be kept\n","  dropout = tf.layers.dropout(\n","      inputs=dense,\n","      rate=0.4,\n","      training= (mode==tf.estimator.ModeKeys.TRAIN) )\n","  # Input Tensor Shape: [batch_size, 5120]\n","  # Output Tensor Shape: [batch_size, 2]\n","  logits = tf.layers.dense(inputs=dropout, units=2)\n","  \n","  #Modes\n","  #Based on the mode, return a different value\n","  #Modes include: Train, Test, Predict, Eval\n","  \n","  #  Predict Mode\n","  predictions = {\n","      #Generate the logits predictions as a dictionary\n","      #  One key for the flattened convolution features of each input image\n","      \"features_flat\": pool2_flattened,\n","      #  One key for the dense features of each input image\n","      \"features_dense\": dense,\n","      #  One key for the predicted classes from logits\n","      \"classes\": tf.argmax(input=logits,axis=1),\n","      #  One key of the overal logits vector shape\n","      \"probabilities\": tf.nn.softmax(logits,name=\"softmax_tensor\")\n","  }\n","  if mode == tf.estimator.ModeKeys.PREDICT:\n","    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n","  \n","  #  Train & Eval Mode\n","  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","  #  Train\n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n","    train_op = optimizer.minimize(\n","        loss=loss,\n","        global_step=tf.train.get_global_step()\n","    )\n","    return tf.estimator.EstimatorSpec(\n","        mode=mode,\n","        loss=loss,\n","        train_op=train_op\n","    )\n","  \n","  #  Eval\n","  eval_metric_ops = {\n","      #Generate the evaluation metrics as a dictionary\n","      \"accuracy\": tf.metrics.accuracy(\n","          labels=labels,\n","          predictions=predictions[\"classes\"]\n","      )\n","  }\n","  return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      loss=loss,\n","      eval_metric_ops=eval_metric_ops\n","  )\n","\n","#log appropriately\n","#https://stackoverflow.com/questions/46013115/how-to-change-global-step-in-tensorflows-skcompat\n","config = tf.estimator.RunConfig(\n","  save_summary_steps=100,\n","  log_step_count_steps=100 #this is where we display log outputs. should be a factor of training \"steps\" below\n",")\n","\n","  #create correct estimator using the custom \"cnn_model_fn\" defined above\n","digit_classifier = tf.estimator.Estimator(\n","  model_fn=cnn_model_fn,\n","  model_dir='./drive/My Drive/Final/tf_cnn_checkpoint/tf_cnn_spectograph_model',\n","  config=config\n",")\n","  \n","  #log progress while training\n","tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n","logging_hook = tf.train.LoggingTensorHook(\n","  tensors=tensors_to_log,\n","  every_n_iter=1000 #Only affect the long log output. Does not affect how frequently we see \"steps\" in output. If not divisible by number of steps, it will take precedence. IE log_iter=5, #steps=11 -> Training will last for 16steps\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': './drive/My Drive/Final/tf_cnn_checkpoint/tf_cnn_spectograph_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7d271fc550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"metadata":{"id":"F4Yx4c4d49K0","colab_type":"code","outputId":"06fc98b5-1617-4d3a-af2f-9a0aec412efd","executionInfo":{"status":"ok","timestamp":1544890984209,"user_tz":420,"elapsed":1042628,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}},"colab":{"base_uri":"https://localhost:8080/","height":3833}},"cell_type":"code","source":["#prepare training input with shuffling, batching, etc\n","  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": X},\n","    y=Y,\n","    batch_size=50,\n","    num_epochs=None,\n","    shuffle=True\n","  )\n","  \n","  ##train the model by calling \"estimator.train\"\n","  digit_classifier.train(\n","    input_fn=train_input_fn,\n","    steps=10000, #Batch size = 50, total data = 300, so there are 6 steps in one epoch, we'll do 4 epochs or 32 steps over a total of 1,200 images\n","    hooks=None #[logging_hook]\n","  )"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","INFO:tensorflow:Saving checkpoints for 0 into ./drive/My Drive/Final/tf_cnn_checkpoint/tf_cnn_spectograph_model/model.ckpt.\n","INFO:tensorflow:loss = 7.731426239013672, step = 0\n","INFO:tensorflow:global_step/sec: 9.55604\n","INFO:tensorflow:loss = 0.6413485407829285, step = 100 (10.466 sec)\n","INFO:tensorflow:global_step/sec: 9.58573\n","INFO:tensorflow:loss = 0.6296758651733398, step = 200 (10.436 sec)\n","INFO:tensorflow:global_step/sec: 9.62526\n","INFO:tensorflow:loss = 0.5851700305938721, step = 300 (10.390 sec)\n","INFO:tensorflow:global_step/sec: 9.63908\n","INFO:tensorflow:loss = 0.5676779747009277, step = 400 (10.374 sec)\n","INFO:tensorflow:global_step/sec: 9.63845\n","INFO:tensorflow:loss = 0.4822348654270172, step = 500 (10.374 sec)\n","INFO:tensorflow:global_step/sec: 9.67201\n","INFO:tensorflow:loss = 0.49738410115242004, step = 600 (10.336 sec)\n","INFO:tensorflow:global_step/sec: 9.66922\n","INFO:tensorflow:loss = 0.5577835440635681, step = 700 (10.342 sec)\n","INFO:tensorflow:global_step/sec: 9.69898\n","INFO:tensorflow:loss = 0.5535838007926941, step = 800 (10.315 sec)\n","INFO:tensorflow:global_step/sec: 9.68237\n","INFO:tensorflow:loss = 0.5086571574211121, step = 900 (10.326 sec)\n","INFO:tensorflow:global_step/sec: 9.66641\n","INFO:tensorflow:loss = 0.5101416110992432, step = 1000 (10.345 sec)\n","INFO:tensorflow:global_step/sec: 9.67485\n","INFO:tensorflow:loss = 0.532084047794342, step = 1100 (10.336 sec)\n","INFO:tensorflow:global_step/sec: 9.70272\n","INFO:tensorflow:loss = 0.3783663809299469, step = 1200 (10.308 sec)\n","INFO:tensorflow:global_step/sec: 9.68108\n","INFO:tensorflow:loss = 0.4968118965625763, step = 1300 (10.329 sec)\n","INFO:tensorflow:global_step/sec: 9.69838\n","INFO:tensorflow:loss = 0.5176125764846802, step = 1400 (10.310 sec)\n","INFO:tensorflow:global_step/sec: 9.67166\n","INFO:tensorflow:loss = 0.3905879259109497, step = 1500 (10.342 sec)\n","INFO:tensorflow:global_step/sec: 9.70987\n","INFO:tensorflow:loss = 0.3358759880065918, step = 1600 (10.296 sec)\n","INFO:tensorflow:global_step/sec: 9.71832\n","INFO:tensorflow:loss = 0.45213583111763, step = 1700 (10.292 sec)\n","INFO:tensorflow:global_step/sec: 9.70557\n","INFO:tensorflow:loss = 0.3886067569255829, step = 1800 (10.300 sec)\n","INFO:tensorflow:global_step/sec: 9.68713\n","INFO:tensorflow:loss = 0.39548859000205994, step = 1900 (10.322 sec)\n","INFO:tensorflow:global_step/sec: 9.71024\n","INFO:tensorflow:loss = 0.38045722246170044, step = 2000 (10.298 sec)\n","INFO:tensorflow:global_step/sec: 9.70191\n","INFO:tensorflow:loss = 0.3467983305454254, step = 2100 (10.308 sec)\n","INFO:tensorflow:global_step/sec: 9.7078\n","INFO:tensorflow:loss = 0.42854124307632446, step = 2200 (10.302 sec)\n","INFO:tensorflow:global_step/sec: 9.70718\n","INFO:tensorflow:loss = 0.39885348081588745, step = 2300 (10.304 sec)\n","INFO:tensorflow:global_step/sec: 9.72169\n","INFO:tensorflow:loss = 0.41326677799224854, step = 2400 (10.286 sec)\n","INFO:tensorflow:global_step/sec: 9.69631\n","INFO:tensorflow:loss = 0.31370237469673157, step = 2500 (10.310 sec)\n","INFO:tensorflow:global_step/sec: 9.71822\n","INFO:tensorflow:loss = 0.40837982296943665, step = 2600 (10.291 sec)\n","INFO:tensorflow:global_step/sec: 9.69664\n","INFO:tensorflow:loss = 0.32753318548202515, step = 2700 (10.315 sec)\n","INFO:tensorflow:global_step/sec: 9.73415\n","INFO:tensorflow:loss = 0.380068302154541, step = 2800 (10.274 sec)\n","INFO:tensorflow:global_step/sec: 9.69695\n","INFO:tensorflow:loss = 0.2501857280731201, step = 2900 (10.308 sec)\n","INFO:tensorflow:global_step/sec: 9.71489\n","INFO:tensorflow:loss = 0.23186664283275604, step = 3000 (10.298 sec)\n","INFO:tensorflow:global_step/sec: 9.69578\n","INFO:tensorflow:loss = 0.22704669833183289, step = 3100 (10.313 sec)\n","INFO:tensorflow:global_step/sec: 9.68844\n","INFO:tensorflow:loss = 0.30944567918777466, step = 3200 (10.323 sec)\n","INFO:tensorflow:global_step/sec: 9.72068\n","INFO:tensorflow:loss = 0.23193353414535522, step = 3300 (10.287 sec)\n","INFO:tensorflow:global_step/sec: 9.69902\n","INFO:tensorflow:loss = 0.2866734266281128, step = 3400 (10.308 sec)\n","INFO:tensorflow:global_step/sec: 9.71219\n","INFO:tensorflow:loss = 0.25167667865753174, step = 3500 (10.300 sec)\n","INFO:tensorflow:global_step/sec: 9.69974\n","INFO:tensorflow:loss = 0.2410556674003601, step = 3600 (10.307 sec)\n","INFO:tensorflow:global_step/sec: 9.69985\n","INFO:tensorflow:loss = 0.2600070834159851, step = 3700 (10.312 sec)\n","INFO:tensorflow:global_step/sec: 9.70564\n","INFO:tensorflow:loss = 0.1437465101480484, step = 3800 (10.303 sec)\n","INFO:tensorflow:global_step/sec: 9.6691\n","INFO:tensorflow:loss = 0.26783430576324463, step = 3900 (10.338 sec)\n","INFO:tensorflow:global_step/sec: 9.69066\n","INFO:tensorflow:loss = 0.14111152291297913, step = 4000 (10.323 sec)\n","INFO:tensorflow:global_step/sec: 9.73514\n","INFO:tensorflow:loss = 0.2119223177433014, step = 4100 (10.272 sec)\n","INFO:tensorflow:global_step/sec: 9.74763\n","INFO:tensorflow:loss = 0.17827102541923523, step = 4200 (10.255 sec)\n","INFO:tensorflow:global_step/sec: 9.73569\n","INFO:tensorflow:loss = 0.22547361254692078, step = 4300 (10.277 sec)\n","INFO:tensorflow:global_step/sec: 9.75742\n","INFO:tensorflow:loss = 0.1889835149049759, step = 4400 (10.247 sec)\n","INFO:tensorflow:global_step/sec: 9.75513\n","INFO:tensorflow:loss = 0.2556672990322113, step = 4500 (10.247 sec)\n","INFO:tensorflow:global_step/sec: 9.74389\n","INFO:tensorflow:loss = 0.20665660500526428, step = 4600 (10.267 sec)\n","INFO:tensorflow:global_step/sec: 9.74475\n","INFO:tensorflow:loss = 0.19544929265975952, step = 4700 (10.261 sec)\n","INFO:tensorflow:global_step/sec: 9.70739\n","INFO:tensorflow:loss = 0.1927894800901413, step = 4800 (10.302 sec)\n","INFO:tensorflow:global_step/sec: 9.74695\n","INFO:tensorflow:loss = 0.12113133072853088, step = 4900 (10.261 sec)\n","INFO:tensorflow:global_step/sec: 9.72537\n","INFO:tensorflow:loss = 0.15609407424926758, step = 5000 (10.282 sec)\n","INFO:tensorflow:global_step/sec: 9.70398\n","INFO:tensorflow:loss = 0.19653499126434326, step = 5100 (10.304 sec)\n","INFO:tensorflow:global_step/sec: 9.72334\n","INFO:tensorflow:loss = 0.1454038918018341, step = 5200 (10.285 sec)\n","INFO:tensorflow:global_step/sec: 9.70795\n","INFO:tensorflow:loss = 0.19120760262012482, step = 5300 (10.301 sec)\n","INFO:tensorflow:global_step/sec: 9.71808\n","INFO:tensorflow:loss = 0.12482736259698868, step = 5400 (10.290 sec)\n","INFO:tensorflow:global_step/sec: 9.68361\n","INFO:tensorflow:loss = 0.11015059053897858, step = 5500 (10.327 sec)\n","INFO:tensorflow:global_step/sec: 9.68837\n","INFO:tensorflow:loss = 0.176619753241539, step = 5600 (10.325 sec)\n","INFO:tensorflow:global_step/sec: 9.7137\n","INFO:tensorflow:loss = 0.07247692346572876, step = 5700 (10.292 sec)\n","INFO:tensorflow:Saving checkpoints for 5800 into ./drive/My Drive/Final/tf_cnn_checkpoint/tf_cnn_spectograph_model/model.ckpt.\n","INFO:tensorflow:global_step/sec: 8.0228\n","INFO:tensorflow:loss = 0.09282635152339935, step = 5800 (12.465 sec)\n","INFO:tensorflow:global_step/sec: 9.71037\n","INFO:tensorflow:loss = 0.08771049231290817, step = 5900 (10.296 sec)\n","INFO:tensorflow:global_step/sec: 9.65768\n","INFO:tensorflow:loss = 0.14011624455451965, step = 6000 (10.354 sec)\n","INFO:tensorflow:global_step/sec: 9.70446\n","INFO:tensorflow:loss = 0.10294707119464874, step = 6100 (10.307 sec)\n","INFO:tensorflow:global_step/sec: 9.71018\n","INFO:tensorflow:loss = 0.10244857519865036, step = 6200 (10.298 sec)\n","INFO:tensorflow:global_step/sec: 9.7098\n","INFO:tensorflow:loss = 0.0900709480047226, step = 6300 (10.299 sec)\n","INFO:tensorflow:global_step/sec: 9.68475\n","INFO:tensorflow:loss = 0.05188708007335663, step = 6400 (10.323 sec)\n","INFO:tensorflow:global_step/sec: 9.7243\n","INFO:tensorflow:loss = 0.06498779356479645, step = 6500 (10.283 sec)\n","INFO:tensorflow:global_step/sec: 9.68663\n","INFO:tensorflow:loss = 0.0844360813498497, step = 6600 (10.322 sec)\n","INFO:tensorflow:global_step/sec: 9.69298\n","INFO:tensorflow:loss = 0.12723368406295776, step = 6700 (10.321 sec)\n","INFO:tensorflow:global_step/sec: 9.72552\n","INFO:tensorflow:loss = 0.1154598817229271, step = 6800 (10.282 sec)\n","INFO:tensorflow:global_step/sec: 9.72425\n","INFO:tensorflow:loss = 0.0469554178416729, step = 6900 (10.284 sec)\n","INFO:tensorflow:global_step/sec: 9.7197\n","INFO:tensorflow:loss = 0.11954597383737564, step = 7000 (10.286 sec)\n","INFO:tensorflow:global_step/sec: 9.69454\n","INFO:tensorflow:loss = 0.10899504274129868, step = 7100 (10.317 sec)\n","INFO:tensorflow:global_step/sec: 9.70888\n","INFO:tensorflow:loss = 0.06361627578735352, step = 7200 (10.300 sec)\n","INFO:tensorflow:global_step/sec: 9.72872\n","INFO:tensorflow:loss = 0.06313740462064743, step = 7300 (10.280 sec)\n","INFO:tensorflow:global_step/sec: 9.72165\n","INFO:tensorflow:loss = 0.04894478619098663, step = 7400 (10.287 sec)\n","INFO:tensorflow:global_step/sec: 9.68961\n","INFO:tensorflow:loss = 0.08519778400659561, step = 7500 (10.319 sec)\n","INFO:tensorflow:global_step/sec: 9.71019\n","INFO:tensorflow:loss = 0.10701979696750641, step = 7600 (10.296 sec)\n","INFO:tensorflow:global_step/sec: 9.69866\n","INFO:tensorflow:loss = 0.0900157019495964, step = 7700 (10.312 sec)\n","INFO:tensorflow:global_step/sec: 9.68566\n","INFO:tensorflow:loss = 0.06201675161719322, step = 7800 (10.327 sec)\n","INFO:tensorflow:global_step/sec: 9.71286\n","INFO:tensorflow:loss = 0.13979890942573547, step = 7900 (10.291 sec)\n","INFO:tensorflow:global_step/sec: 9.69915\n","INFO:tensorflow:loss = 0.05560695379972458, step = 8000 (10.316 sec)\n","INFO:tensorflow:global_step/sec: 9.68443\n","INFO:tensorflow:loss = 0.05904388800263405, step = 8100 (10.324 sec)\n","INFO:tensorflow:global_step/sec: 9.68301\n","INFO:tensorflow:loss = 0.06247435882687569, step = 8200 (10.325 sec)\n","INFO:tensorflow:global_step/sec: 9.68472\n","INFO:tensorflow:loss = 0.06235074996948242, step = 8300 (10.326 sec)\n","INFO:tensorflow:global_step/sec: 9.69429\n","INFO:tensorflow:loss = 0.027924777939915657, step = 8400 (10.315 sec)\n","INFO:tensorflow:global_step/sec: 9.67516\n","INFO:tensorflow:loss = 0.04562694951891899, step = 8500 (10.336 sec)\n","INFO:tensorflow:global_step/sec: 9.67444\n","INFO:tensorflow:loss = 0.046843912452459335, step = 8600 (10.338 sec)\n","INFO:tensorflow:global_step/sec: 9.68324\n","INFO:tensorflow:loss = 0.042667780071496964, step = 8700 (10.327 sec)\n","INFO:tensorflow:global_step/sec: 9.73396\n","INFO:tensorflow:loss = 0.0343920923769474, step = 8800 (10.272 sec)\n","INFO:tensorflow:global_step/sec: 9.67588\n","INFO:tensorflow:loss = 0.05322640389204025, step = 8900 (10.333 sec)\n","INFO:tensorflow:global_step/sec: 9.67078\n","INFO:tensorflow:loss = 0.022940918803215027, step = 9000 (10.343 sec)\n","INFO:tensorflow:global_step/sec: 9.71241\n","INFO:tensorflow:loss = 0.05966086685657501, step = 9100 (10.297 sec)\n","INFO:tensorflow:global_step/sec: 9.67801\n","INFO:tensorflow:loss = 0.0634947121143341, step = 9200 (10.332 sec)\n","INFO:tensorflow:global_step/sec: 9.69025\n","INFO:tensorflow:loss = 0.028657611459493637, step = 9300 (10.318 sec)\n","INFO:tensorflow:global_step/sec: 9.6846\n","INFO:tensorflow:loss = 0.060106974095106125, step = 9400 (10.324 sec)\n","INFO:tensorflow:global_step/sec: 9.69459\n","INFO:tensorflow:loss = 0.017515284940600395, step = 9500 (10.315 sec)\n","INFO:tensorflow:global_step/sec: 9.67696\n","INFO:tensorflow:loss = 0.03226276859641075, step = 9600 (10.336 sec)\n","INFO:tensorflow:global_step/sec: 9.68208\n","INFO:tensorflow:loss = 0.03692963346838951, step = 9700 (10.329 sec)\n","INFO:tensorflow:global_step/sec: 9.68485\n","INFO:tensorflow:loss = 0.04943130537867546, step = 9800 (10.325 sec)\n","INFO:tensorflow:global_step/sec: 9.67108\n","INFO:tensorflow:loss = 0.08288978040218353, step = 9900 (10.340 sec)\n","INFO:tensorflow:Saving checkpoints for 10000 into ./drive/My Drive/Final/tf_cnn_checkpoint/tf_cnn_spectograph_model/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.038515519350767136.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.estimator.estimator.Estimator at 0x7f7d271fc320>"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"ozULOvPblQWy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Add ops to save and restore all the variables.\n","saver = tf.train.Saver()\n","\n","# Later, launch the model, use the saver to restore variables from disk, and\n","# do some work with the model.\n","with tf.Session() as sess:\n","  # Restore variables from disk.\n","  saver.restore(sess, \"/tmp/model.ckpt\")\n","  print(\"Model restored.\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4iEREnwCfLnk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"307c7e19-5ba2-406d-c924-c33db7ead6e1","executionInfo":{"status":"ok","timestamp":1544891594894,"user_tz":420,"elapsed":1748,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}}},"cell_type":"code","source":["\n","predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n","      x={\"x\":X},\n","      num_epochs=1,\n","      shuffle=False)\n","predictions = digit_classifier.predict(input_fn=predict_input_fn)\n","features = np.zeros((len(X), 10*16*64))\n","for i in range(len(X)):\n","  eachdata = next(predictions)\n","  features[i,:] = eachdata['features_flat']"],"execution_count":11,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from ./drive/My Drive/Final/tf_cnn_checkpoint/tf_cnn_spectograph_model/model.ckpt-10000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"}]},{"metadata":{"id":"JmLSJSGOjfQP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"3c2cca1a-dec7-4aed-b2df-aff24555e2bf","executionInfo":{"status":"ok","timestamp":1544891675901,"user_tz":420,"elapsed":236,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}}},"cell_type":"code","source":["with open('./drive/My Drive/Final/CNN_data/feature_extracted', 'wb') as f:\n","  np.save(f, features)\n"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4.67980140e-06, 0.00000000e+00, 0.00000000e+00, ...,\n","       4.10164371e-03, 0.00000000e+00, 0.00000000e+00])"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"M7TOA3kVuDN0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"16afb9b5-af67-40d8-b792-d6435917ae55","executionInfo":{"status":"ok","timestamp":1544891697477,"user_tz":420,"elapsed":234,"user":{"displayName":"Mingcan Tang","photoUrl":"https://lh3.googleusercontent.com/-_szpxh5fj0A/AAAAAAAAAAI/AAAAAAAAALc/Tv2i7BqkzVY/s64/photo.jpg","userId":"09161304890180913859"}}},"cell_type":"code","source":["max(features[0])"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.1593384792391646"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"SYlRitgxuIfX","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}